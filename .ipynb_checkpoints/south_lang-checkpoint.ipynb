{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dba036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    }
   ],
   "source": [
    "# Importing comet_ml\n",
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "#from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "# Creating an experiment with api key\n",
    "\n",
    "experiment = Experiment(\n",
    "  api_key = \"Z3zS1quxrC1NIIK61rNNhVKdg\",\n",
    "  project_name = \"Language Classification\",\n",
    "  workspace=\"sorach-roshe\"\n",
    ")\n",
    "# suppress cell warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "# Importing the Libraries \n",
    "import re  # for pattern matching and manipulation of strings.\n",
    "import numpy as np  # used for numerical computations and data manipulation.\n",
    "import pandas as pd  # for data manipulation and analysis.\n",
    "import string  # for string manipulation tasks.\n",
    "\n",
    "# For plotting\n",
    "import seaborn as sns  # for data visualization.\n",
    "from wordcloud import WordCloud  # used to generate word clouds.\n",
    "import matplotlib.pyplot as plt  # used for plotting data.\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer  # used for lemmatizing words\n",
    "from nltk.tokenize import TreebankWordTokenizer  # used for tokenizing sentences into words.\n",
    "from nltk import SnowballStemmer  # used for stemming words.\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC  # used for solving linear classification problems. \n",
    "from sklearn.naive_bayes import BernoulliNB  # implementation of the Naive Bayes algorithm.\n",
    "from sklearn.linear_model import LogisticRegression  # implementation of logistic regression.  \n",
    "from sklearn.model_selection import train_test_split  # for splitting a dataset into training and testing subsets.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # for converting text documents into a numerical representation.\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # for evaluating the performance of a classification model\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn import preprocessing  # for data preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import timeit\n",
    "# suppress cell warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_set.csv\") # reads a CSV file named \"train.csv\" and stores it in Pandas df.\n",
    "df_test = pd.read_csv(\"test_set.csv\") # reads \"test_with_no_labels.csv\" and stores it in Pandas df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170af2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b47ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251790ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7deef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419003ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the datasets\n",
    "print(f'The shape of the train dataset: {df.shape}\\nThe shape of the test dataset: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ec936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8e64c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To creates a countplot\n",
    "sns.countplot(x='lang_id', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution for dataset.\n",
    "ax = df.groupby('lang_id').count().plot(kind='bar', title='Distribution of data',legend=False)\n",
    "ax.set_xticklabels(['xho','eng','nso','ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso', 'sot', 'afr'], rotation=0)\n",
    "# Storing data in lists.\n",
    "text, lang_id = list(df['text']), list(df['lang_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01918c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Separating languages by number\n",
    "data_1 = df[df['lang_id'] == 'xho']\n",
    "data_2 = df[df['lang_id'] == 'eng']\n",
    "data_3 = df[df['lang_id'] == 'nso' ]\n",
    "data_4 = df[df['lang_id'] == 'ven']\n",
    "data_5 = df[df['lang_id'] == 'tsn']\n",
    "data_6 = df[df['lang_id'] == 'nbl']\n",
    "data_7 = df[df['lang_id'] == 'zul']\n",
    "data_8 = df[df['lang_id'] == 'ssw']\n",
    "data_9 = df[df['lang_id'] == 'tso']\n",
    "data_10 = df[df['lang_id'] == 'sot']\n",
    "data_11 = df[df['lang_id'] == 'afr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all\n",
    "dataset = pd.concat([data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10, data_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a44032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to lowercase\n",
    "dataset['text']=dataset['text'].str.lower()\n",
    "df_test['text'] = df_test['text'].str.lower()\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888336e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['text'].apply(remove_punctuation)\n",
    "df_test['text'] = df_test['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "dataset['tokens'] = dataset['text'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating input feature and label\n",
    "X = dataset.text\n",
    "y = dataset.lang_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the 80% data for training data and 20% for testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Dataset Using TF-IDF Vectorizer\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,3), max_features=500000)\n",
    "vectoriser.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vectoriser.transform(X_train)\n",
    "X_test_vect = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = vectoriser.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Evaluate(model):\n",
    "    # Predict values for Test dataset\n",
    "    y_pred = model.predict(X_test_vect)\n",
    "    # Print the evaluation metrics for the dataset.\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad5670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bernoulli model\n",
    "BNBmodel = BernoulliNB()\n",
    "BNBmodel.fit(X_train_vect, y_train)\n",
    "model_Evaluate(BNBmodel)\n",
    "y_pred1 = BNBmodel.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9dd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.iloc[:len(y_pred1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = y_pred1[:len(df_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_bern = pd.DataFrame({'index': df_test['index'], 'lang_id': y_pred1})\n",
    "results_df_bern.to_csv('results_df_bern.csv', index=False)\n",
    "results_df_bern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_bern.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df75723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC model\n",
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(X_train_vect, y_train)\n",
    "model_Evaluate(SVCmodel)\n",
    "y_pred2 = SVCmodel.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6712a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = y_pred1[:len(df_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a78c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_svc = pd.DataFrame({'index': df_test['index'], 'lang_id': y_pred2})\n",
    "results_df_svc.to_csv('results_df_svc.csv', index=False)\n",
    "results_df_svc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
